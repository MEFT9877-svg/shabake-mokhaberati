{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import os\n",
        "import numpy as np\n",
        "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
        "from stable_baselines3.common.logger import HParam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Custom callback for plotting additional values in tensorboard.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, verbose=1):\n",
        "        super(TensorboardCallback, self).__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        self.logger.record('reward', self.training_env.get_attr('reward')[0])\n",
        "        self.logger.record('cum_reward', self.training_env.get_attr('episode_reward')[0])\n",
        "        self.logger.dump(self.num_timesteps)\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
        "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
        "\n",
        "    :param check_freq: (int)\n",
        "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
        "      It must contains the file created by the ``Monitor`` wrapper.\n",
        "    :param verbose: (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, check_freq, log_dir, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.log_dir = log_dir\n",
        "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
        "        self.best_mean_reward = -np.inf\n",
        "\n",
        "    def _init_callback(self) -> None:\n",
        "        # Create folder if needed\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "\n",
        "            # Retrieve training reward\n",
        "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
        "            if len(x) > 0:\n",
        "                # Mean training reward over the last 100 episodes\n",
        "                mean_reward = np.mean(y[-100:])\n",
        "                if self.verbose > 0:\n",
        "                    print(\"Num timesteps: {}\".format(self.num_timesteps))\n",
        "                    print(\n",
        "                        \"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(\n",
        "                            self.best_mean_reward, mean_reward\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                # New best model, you could save the agent here\n",
        "                if mean_reward > self.best_mean_reward:\n",
        "                    self.best_mean_reward = mean_reward\n",
        "                    # Example for saving best model\n",
        "                    if self.verbose > 0:\n",
        "                        print(\"Saving new best model at {} timesteps\".format(x[-1]))\n",
        "                        print(\"Saving new best model to {}.zip\".format(self.save_path))\n",
        "                    self.model.save(self.save_path)\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "\n",
        "class HParamCallback(BaseCallback):\n",
        "\n",
        "    def __init__(self, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "    \"\"\"\n",
        "    Saves the hyperparameters and metrics at the start of the training, and logs them to TensorBoard.\n",
        "    \"\"\"\n",
        "\n",
        "    def _on_training_start(self) -> None:\n",
        "        hparam_dict = {\n",
        "            \"algorithm\": self.model.__class__.__name__,\n",
        "            \"learning rate\": self.model.learning_rate,\n",
        "            \"gamma\": self.model.gamma,\n",
        "        }\n",
        "        # define the metrics that will appear in the `HPARAMS` Tensorboard tab by referencing their tag\n",
        "        # Tensorbaord will find & display metrics from the `SCALARS` tab\n",
        "        metric_dict = {\n",
        "            \"rollout/ep_len_mean\": 0,\n",
        "            \"rollout/ep_rew_mean\": 0,\n",
        "            \"train/value_loss\": 0.0,\n",
        "            \"train/actor_loss\": 0.0,\n",
        "        }\n",
        "        self.logger.record(\n",
        "            \"hparams\",\n",
        "            HParam(hparam_dict, metric_dict),\n",
        "            exclude=(\"stdout\", \"log\", \"json\", \"csv\"),\n",
        "        )\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        return True\n",
        "\n",
        "\n",
        "class MeticLogger(BaseCallback):\n",
        "    def __init__(self,log_frequency=10, verbose=1):\n",
        "        super(MeticLogger, self).__init__(verbose)\n",
        "        self.verbose=verbose\n",
        "        self.log_frequency=log_frequency\n",
        "        self.value_lossess=[]\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.log_frequency == 0:\n",
        "            if (self.verbose == 1):\n",
        "                print(f\"iterations: {self.model.logger.name_to_value['train/n_updates']}\")\n",
        "                print(f\"ep_rew_mean: {self.model.logger.name_to_value['train/ep_rew_mean']}\")\n",
        "                print(f\"policy_loss: {self.model.logger.name_to_value['train/policy_loss']}\")\n",
        "                print(f\"value_loss: {self.model.logger.name_to_value['train/value_loss']}\")\n",
        "                print(f\"entropy_loss: {self.model.logger.name_to_value['train/entropy_loss']}\")\n",
        "                print(\"--------------------------------\")\n",
        "                self.value_lossess.append(self.model.logger.name_to_value['train/value_loss'])\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "class PlottingCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Callback for plotting the performance in realtime.\n",
        "\n",
        "    :param verbose: (int)\n",
        "    \"\"\"\n",
        "    def __init__(self, log_dir, verbose=1):\n",
        "        super().__init__(verbose)\n",
        "        self._plot = None\n",
        "        self.log_dir = log_dir\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # get the monitor's data\n",
        "        x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
        "        if self._plot is None: # make the plot\n",
        "            plt.ion()\n",
        "            fig = plt.figure(figsize=(6,3))\n",
        "            ax = fig.add_subplot(111)\n",
        "            line, = ax.plot(x, y)\n",
        "            self._plot = (line, ax, fig)\n",
        "            plt.show()\n",
        "        else: # update and rescale the plot\n",
        "            self._plot[0].set_data(x, y)\n",
        "            self._plot[-2].relim()\n",
        "            self._plot[-2].set_xlim([self.locals[\"total_timesteps\"] * -0.02,\n",
        "                                    self.locals[\"total_timesteps\"] * 1.02])\n",
        "            self._plot[-2].autoscale_view(True,True,True)\n",
        "            self._plot[-1].canvas.draw()\n",
        ""
      ],
      "metadata": {
        "id": "AzS23btex0S3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}